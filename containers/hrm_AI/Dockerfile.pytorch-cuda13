# HRM Training Container - Ubuntu 24.04 / CUDA 13 / PyTorch (NVIDIA NGC)
FROM nvcr.io/nvidia/pytorch:25.06-py3

ENV DEBIAN_FRONTEND=noninteractive \
    PIP_NO_CACHE_DIR=1 \
    PYTHONUNBUFFERED=1 \
    TZ=UTC

# System deps and Python basics
RUN apt-get update && apt-get install -y --no-install-recommends \
    git curl ca-certificates build-essential pkg-config \
    python3-dev python3-venv \
    && rm -rf /var/lib/apt/lists/*

# Optional: FlashAttention (SM_120 readiness may be pending); prefer SDPA fallback
# Here we install common training deps; FA can be toggled via build args later.
RUN pip install --upgrade pip wheel setuptools && \
    pip install wandb packaging ninja setuptools-scm hydra-core==1.3.2 \
                numpy einops tqdm coolname argdantic pydantic-settings python-dotenv huggingface_hub \
                onnx onnxruntime-gpu==1.19.0 \
                torch-tensorrt -f https://github.com/pytorch/TensorRT/releases/expanded_assets/v2.4.0

# Ensure SM_120 CUDA extensions can build (e.g., adam-atan2)
ENV TORCH_CUDA_ARCH_LIST="12.0+PTX" \
    PIP_BREAK_SYSTEM_PACKAGES=1

# Pre-build adam-atan2 against SM_120 to avoid runtime kernel errors
RUN pip install --no-binary=:all: adam-atan2==0.0.3 || true

# Create workspace
WORKDIR /workspace

# Add entrypoint for auto W&B login via env var
COPY containers/hrm/entrypoint.sh /usr/local/bin/hrm-entrypoint
RUN chmod +x /usr/local/bin/hrm-entrypoint

# Default command
ENTRYPOINT ["/usr/local/bin/hrm-entrypoint"]
CMD ["bash"]

