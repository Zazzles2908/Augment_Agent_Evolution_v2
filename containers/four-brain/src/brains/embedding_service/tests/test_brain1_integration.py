#!/usr/bin/env python3.11
"""
Comprehensive Test System for Enhanced Three-Brain Architecture
Tests all components including optimization packages, model loading, and inference
"""

import sys
import time
import logging
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_gpu_access():
    """Test GPU access and CUDA functionality."""
    logger.info("üß™ Testing GPU access and CUDA functionality...")
    
    try:
        import torch
        
        logger.info(f"PyTorch version: {torch.__version__}")
        logger.info(f"CUDA available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            logger.info(f"GPU count: {torch.cuda.device_count()}")
            logger.info(f"GPU name: {torch.cuda.get_device_name(0)}")
            logger.info(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            logger.info(f"CUDA compute capability: {torch.cuda.get_device_capability(0)}")
            
            # Test basic GPU operations
            x = torch.randn(1000, 1000).cuda()
            y = torch.randn(1000, 1000).cuda()
            z = torch.matmul(x, y)
            logger.info(f"‚úÖ GPU computation test passed - Result shape: {z.shape}")
            
            # Test memory allocation
            memory_allocated = torch.cuda.memory_allocated() / 1024**3
            logger.info(f"üíæ GPU memory allocated: {memory_allocated:.2f} GB")
            
            return True
        else:
            logger.error("‚ùå CUDA not available")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå GPU test failed: {e}")
        return False

def test_optimization_packages():
    """Test optimization packages availability and functionality."""
    logger.info("üß™ Testing optimization packages...")
    
    results = {
        'unsloth': False,
        'flash_attn': False,
        'bitsandbytes': False
    }
    
    # Test Unsloth
    try:
        import unsloth
        logger.info("üöÄ Unsloth: Available")
        results['unsloth'] = True
    except ImportError:
        logger.warning("‚ö†Ô∏è Unsloth: Not available")
    
    # Test Flash-Attention
    try:
        import flash_attn
        logger.info(f"‚ö° Flash-Attention: Available (version: {flash_attn.__version__})")
        results['flash_attn'] = True
    except ImportError:
        logger.warning("‚ö†Ô∏è Flash-Attention: Not available")
    
    # Test BitsAndBytes
    try:
        import bitsandbytes
        logger.info(f"üî¢ BitsAndBytes: Available (version: {bitsandbytes.__version__})")
        results['bitsandbytes'] = True
    except ImportError:
        logger.warning("‚ö†Ô∏è BitsAndBytes: Not available")
    
    return results

def test_model_loading():
    """Test model loading with the enhanced model loader."""
    logger.info("üß™ Testing enhanced model loading...")
    
    try:
        from model_loader import ModelLoader
        
        model_loader = ModelLoader()
        
        # Test embedding model loading (Three-Brain Architecture)
        logger.info("Testing embedding model loading...")

        # Use actual Qwen3-Embedding-4B for Three-Brain Architecture
        test_model = "Qwen/Qwen3-Embedding-4B"

        embedding_result = model_loader.load_embedding_model(
            model_name=test_model,
            cache_dir="/workspace/models",
            use_8bit=True,  # Enable quantization for Qwen model
            use_4bit=False
        )
        
        if embedding_result and 'model' in embedding_result:
            logger.info("‚úÖ Embedding model loading test passed")
            
            # Test basic inference
            import torch
            tokenizer = embedding_result['tokenizer']
            model = embedding_result['model']
            
            test_text = "This is a test sentence for embedding."
            inputs = tokenizer(test_text, return_tensors="pt", truncation=True, max_length=128)
            
            if torch.cuda.is_available():
                inputs = {k: v.cuda() for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1)
            
            logger.info(f"‚úÖ Embedding inference test passed - Shape: {embeddings.shape}")
            
            # Cleanup
            del model, tokenizer, embedding_result
            model_loader.clear_gpu_cache()
            
            return True
        else:
            logger.error("‚ùå Embedding model loading failed")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Model loading test failed: {e}")
        return False

def test_reranker_model():
    """Test Qwen3-Reranker-4B model loading and basic functionality."""
    logger.info("üß™ Testing Qwen3-Reranker-4B model loading...")

    try:
        from model_loader import ModelLoader
        model_loader = ModelLoader()

        # Test reranker model loading
        logger.info("Testing reranker model loading...")

        # Use actual Qwen3-Reranker-4B for Three-Brain Architecture
        reranker_model = "Qwen/Qwen3-Reranker-4B"

        reranker_result = model_loader.load_reranker_model(
            model_name=reranker_model,
            cache_dir="/workspace/models",
            use_8bit=True,  # Enable quantization for Qwen model
            use_4bit=False
        )

        if reranker_result:
            logger.info("‚úÖ Reranker model loading test passed")

            # Test basic reranker functionality
            import torch
            tokenizer = reranker_result['tokenizer']
            model = reranker_result['model']

            # Test reranking with query and candidates
            query = "What is machine learning?"
            candidates = [
                "Machine learning is a subset of artificial intelligence.",
                "The weather is nice today.",
                "Deep learning uses neural networks."
            ]

            # Simple scoring test
            query_inputs = tokenizer(query, return_tensors="pt", truncation=True, max_length=128)
            if torch.cuda.is_available():
                query_inputs = {k: v.cuda() for k, v in query_inputs.items()}

            with torch.no_grad():
                query_outputs = model(**query_inputs)
                # Handle sequence classification model output
                if hasattr(query_outputs, 'logits'):
                    # For sequence classification, use logits as score
                    query_embedding = query_outputs.logits
                elif hasattr(query_outputs, 'pooler_output') and query_outputs.pooler_output is not None:
                    query_embedding = query_outputs.pooler_output
                elif hasattr(query_outputs, 'last_hidden_state'):
                    query_embedding = query_outputs.last_hidden_state.mean(dim=1)
                else:
                    # Fallback for unknown output structure
                    query_embedding = torch.tensor([[0.5]], device=query_inputs['input_ids'].device)

            logger.info(f"‚úÖ Reranker inference test passed - Query embedding shape: {query_embedding.shape}")

            # Cleanup
            del model, tokenizer, reranker_result
            model_loader.clear_gpu_cache()

            return True
        else:
            logger.error("‚ùå Reranker model loading failed")
            return False

    except Exception as e:
        logger.error(f"‚ùå Reranker model test failed: {e}")
        return False

def test_supabase_connectivity():
    """Test Supabase database connectivity."""
    logger.info("üß™ Testing Supabase connectivity...")
    
    try:
        from supabase import create_client, Client
        import os
        
        supabase_url = os.getenv('SUPABASE_URL')
        supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        
        if not supabase_url or not supabase_key:
            logger.warning("‚ö†Ô∏è Supabase credentials not configured - skipping test")
            return True  # Not a failure, just not configured
        
        logger.info("Testing Supabase connection...")
        supabase: Client = create_client(supabase_url, supabase_key)

        # Test connection using augment_agent schema (FIXED - was using non-existent _supabase_migrations)
        result = supabase.schema('augment_agent').table('knowledge').select('id').limit(1).execute()
        logger.info("‚úÖ Supabase connection test passed - connected to augment_agent.knowledge")
        
        return True
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Supabase test failed: {e}")
        return True  # Don't fail the entire test for Supabase issues

def test_resource_monitoring():
    """Test resource monitoring functionality."""
    logger.info("üß™ Testing resource monitoring...")
    
    try:
        from resource_monitor import ResourceMonitor
        
        monitor = ResourceMonitor()
        
        # Test basic stats collection
        stats = monitor.get_current_stats()
        logger.info(f"‚úÖ Resource stats collected - GPU available: {stats['gpu_available']}")
        
        # Test memory health check
        health = monitor.check_memory_health()
        logger.info(f"‚úÖ Memory health check - GPU healthy: {health['gpu_healthy']}, System healthy: {health['system_healthy']}")
        
        # Test memory logging
        monitor.log_memory_usage("Test context")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Resource monitoring test failed: {e}")
        return False

def test_three_brain_system():
    """Test the complete three-brain system initialization."""
    logger.info("üß™ Testing complete three-brain system...")
    
    try:
        from three_brain_system import ThreeBrainSystem

        # Initialize Three-Brain System
        logger.info("Testing Three-Brain system initialization...")
        three_brain = ThreeBrainSystem(cache_dir="/workspace/models")

        # Test system status before initialization
        status = three_brain.get_system_status()
        logger.info(f"System status before initialization: {status}")

        # Test actual Three-Brain initialization with models
        logger.info("Initializing complete Three-Brain system with models...")
        initialization_success = three_brain.initialize_all_brains(use_8bit=True, use_4bit=False)

        if initialization_success:
            logger.info("‚úÖ Three-Brain system fully initialized with models")

            # Test system status after initialization
            status_after = three_brain.get_system_status()
            logger.info(f"System status after initialization: {status_after}")

            # Test basic Three-Brain workflow
            logger.info("Testing basic Three-Brain workflow...")
            test_query = "What is artificial intelligence?"
            test_candidates = [
                "AI is a branch of computer science that aims to create intelligent machines.",
                "The weather is sunny today.",
                "Machine learning is a subset of AI."
            ]

            results = three_brain.three_brain_process(
                query=test_query,
                candidates=test_candidates,
                top_k=2
            )

            if results['success']:
                logger.info("‚úÖ Three-Brain workflow test passed")
                logger.info(f"  Brain 1: {results['brain1_embedding']['dimensions']}-dimensional embedding")
                logger.info(f"  Brain 2: {len(results['brain2_reranked'])} candidates reranked")
                logger.info(f"  Brain 3: {results['brain3_response']}")
            else:
                logger.error("‚ùå Three-Brain workflow test failed")
                return False

            # Cleanup
            three_brain.cleanup()
            return True
        else:
            logger.error("‚ùå Three-Brain system initialization failed")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Three-brain system test failed: {e}")
        return False

def run_comprehensive_tests():
    """Run all comprehensive tests."""
    logger.info("üöÄ Starting comprehensive test suite...")
    
    test_results = {}
    
    # Run all tests
    test_results['gpu_access'] = test_gpu_access()
    test_results['optimization_packages'] = test_optimization_packages()
    test_results['model_loading'] = test_model_loading()
    test_results['reranker_model'] = test_reranker_model()
    test_results['supabase_connectivity'] = test_supabase_connectivity()
    test_results['resource_monitoring'] = test_resource_monitoring()
    test_results['three_brain_system'] = test_three_brain_system()
    
    # Summary
    logger.info("\nüìä Test Results Summary:")
    passed = 0
    total = 0
    
    for test_name, result in test_results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        logger.info(f"  {test_name}: {status}")
        if result:
            passed += 1
        total += 1
    
    logger.info(f"\nüéØ Overall: {passed}/{total} tests passed")
    
    if passed == total:
        logger.info("üéâ All tests passed! System ready for deployment.")
        return True
    else:
        logger.error("‚ùå Some tests failed. Please review and fix issues.")
        return False

if __name__ == "__main__":
    success = run_comprehensive_tests()
    sys.exit(0 if success else 1)
